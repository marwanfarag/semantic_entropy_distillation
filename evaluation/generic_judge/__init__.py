"""
Generic Judge Evaluation Package

This package provides tools for evaluating LLM responses using a judge model.
Works with any HuggingFace dataset and supports pairwise model comparison.

Modules:
    - generate_responses: Generate responses for any HF dataset
    - evaluate_with_judge: Evaluate responses using LLM judge
    - compare_models: Pairwise comparison with win rates
"""
